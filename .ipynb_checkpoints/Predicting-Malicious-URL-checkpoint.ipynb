{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9d662a2-8491-4338-a483-95c966e400f8",
   "metadata": {},
   "source": [
    "# Malicious URL Predictor In Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee366373-d7e9-4738-9451-947b6f595ec7",
   "metadata": {},
   "source": [
    "# Step 1: Train and Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d5733f-3cfd-4d4a-8559-6df89cb5377b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import tldextract\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"malicious.csv\")\n",
    "\n",
    "# Map labels to numeric values\n",
    "label_mapping = {'benign': 0, 'defacement': 1, 'phishing': 2, 'malware': 3}\n",
    "df['label'] = df['type'].map(label_mapping)\n",
    "\n",
    "# Feature Extraction Function\n",
    "def extract_features(url):\n",
    "    features = {}\n",
    "    features['url_length'] = len(url)\n",
    "    features['num_digits'] = sum(c.isdigit() for c in url)\n",
    "    features['num_special_chars'] = len(re.findall(r\"[!@#$%^&*(),.?\\\":{}|<>]\", url))\n",
    "    \n",
    "    # Extract domain/subdomain details\n",
    "    extracted = tldextract.extract(url)\n",
    "    features['domain_length'] = len(extracted.domain)\n",
    "    features['subdomain_length'] = len(extracted.subdomain)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Apply feature extraction\n",
    "features_df = df['url'].apply(lambda x: pd.Series(extract_features(x)))\n",
    "\n",
    "# TF-IDF Vectorization on URLs\n",
    "tfidf = TfidfVectorizer(max_features=1000)\n",
    "X_tfidf = tfidf.fit_transform(df['url']).toarray()\n",
    "\n",
    "# Combine extracted numerical features and TF-IDF\n",
    "X_combined = np.hstack((features_df.values, X_tfidf))\n",
    "\n",
    "# Target labels\n",
    "y = df['label']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest Model\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Save model & vectorizer\n",
    "joblib.dump(rf, \"malicious_url_model.pkl\")\n",
    "joblib.dump(tfidf, \"tfidf_vectorizer.pkl\")\n",
    "\n",
    "# Predictions & Evaluation\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Model Training Complete. Model Saved!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1056807-16be-4af6-9fca-ce4a8928611a",
   "metadata": {},
   "source": [
    "# Step 2: Create Flask API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c7e880-7dc9-4eb4-b70a-5fb4511f1b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import tldextract\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load trained model & TF-IDF vectorizer\n",
    "model = joblib.load(\"malicious_url_model.pkl\")\n",
    "vectorizer = joblib.load(\"tfidf_vectorizer.pkl\")\n",
    "\n",
    "# Label mapping\n",
    "label_mapping = {0: 'benign', 1: 'defacement', 2: 'phishing', 3: 'malware'}\n",
    "\n",
    "# Feature Extraction Function\n",
    "def extract_features(url):\n",
    "    features = {}\n",
    "    features['url_length'] = len(url)\n",
    "    features['num_digits'] = sum(c.isdigit() for c in url)\n",
    "    features['num_special_chars'] = len(re.findall(r\"[!@#$%^&*(),.?\\\":{}|<>]\", url))\n",
    "    \n",
    "    extracted = tldextract.extract(url)\n",
    "    features['domain_length'] = len(extracted.domain)\n",
    "    features['subdomain_length'] = len(extracted.subdomain)\n",
    "    \n",
    "    return features\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    try:\n",
    "        data = request.json\n",
    "        url = data.get(\"url\")\n",
    "        if not url:\n",
    "            return jsonify({\"error\": \"URL is required\"}), 400\n",
    "        \n",
    "        # Extract features\n",
    "        features = pd.DataFrame([extract_features(url)])\n",
    "        tfidf_features = vectorizer.transform([url]).toarray()\n",
    "        X_input = np.hstack((features.values, tfidf_features))\n",
    "\n",
    "        # Predict\n",
    "        prediction = model.predict(X_input)\n",
    "        label = label_mapping[prediction[0]]\n",
    "\n",
    "        return jsonify({\"url\": url, \"prediction\": label})\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a7be90-89a0-4f1e-8d37-2fa8bab0d6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
